{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Intermediate Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model, Model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "parent_dir = '../../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load model 3 to try this visual out on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = load_model(parent_dir + 'models/model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remind ourselves of this model's architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Test Image:\n",
    "\n",
    "Select an image from the training set to visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = parent_dir + 'data/seg_train/glacier/10025.jpeg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(256, 256))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "#Follow the Original Model Preprocessing\n",
    "img_tensor /= 255.\n",
    "\n",
    "#Check tensor shape\n",
    "print(img_tensor.shape)\n",
    "\n",
    "#Preview an image\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Output Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model layer outputs\n",
    "layer_outputs = [layer.output for layer in model3.layers[:8]]\n",
    "\n",
    "# Rather then a model with a single output, we are going to make a model to display the feature maps\n",
    "activation_model = Model(inputs = model3.input, outputs = layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array for each activation layer\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "\n",
    "# We slice the third channel and preview the results\n",
    "plt.matshow(first_layer_activation[0, :, :, 3], cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating the process for another channel (the 30th)\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "\n",
    "plt.matshow(first_layer_activation[0, :, :, 30], cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise All 64 Channels of First Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8, 4, figsize=(12,24))\n",
    "for i in range(64):\n",
    "    row = i//4\n",
    "    column = i%4\n",
    "    ax = axes[row, column]\n",
    "    first_layer_activation = activations[0]\n",
    "    ax.matshow(first_layer_activation[0, :, :, i], cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise 5th Channel of Every Model Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,4, figsize=(12,8))\n",
    "\n",
    "layer_names = []\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "for i in range(8):\n",
    "    row = i//4\n",
    "    column = i%4\n",
    "    ax = axes[row, column]\n",
    "    cur_layer = activations[i]\n",
    "    ax.matshow(cur_layer[0, :, :, 5], cmap='viridis')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_title(layer_names[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap-env",
   "language": "python",
   "name": "cap-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
